{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in npy files that were produced from splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the npy files for train, val and test sets\n",
    "x_train = np.load('train_val_test_sets/x_train.npy')\n",
    "y_train = np.load('train_val_test_sets/y_train.npy')\n",
    "\n",
    "x_val = np.load('train_val_test_sets/x_val.npy')\n",
    "y_val = np.load('train_val_test_sets/y_val.npy')\n",
    "\n",
    "x_test = np.load('train_val_test_sets/x_test.npy')\n",
    "y_test = np.load('train_val_test_sets/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for changing the labels for One vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One vs All function. Sorry I named it this way because I am a huge fan of boku no hero\n",
    "def one_for_all(y_arr, the_one):\n",
    "    # y_arr: your labels array input\n",
    "    # the_one: name of the class that will be the one\n",
    "    \n",
    "    ## Class 0 will be the All, Specified class will be the One\n",
    "    new_y = (y_arr == the_one) + 0\n",
    "    \n",
    "    return new_y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for getting class wise accuracy\n",
    "def class_wise_accuracy(actual_y, pred_y, label):\n",
    "    # actual_y: actual y values\n",
    "    # pred_y: predicted y values\n",
    "    # label: class\n",
    "    \n",
    "    acc = (1/np.sum(actual_y == label)) * (np.sum((actual_y == label)*(pred_y == label)))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for vanilla accuracy\n",
    "def vanilla_taste_good(actual_y, pred_y, num_inst):\n",
    "    # actual_y: actual y values\n",
    "    # pred_y: predicted y values\n",
    "    # num_inst: number of instances\n",
    "    \n",
    "    acc = np.sum(pred_y == actual_y) / num_inst\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for converting labels in an array to their respective digit labels using a dictionary for mapping\n",
    "def season_map(y, mapper):\n",
    "    # y: your labels array\n",
    "    # mapper: your dictionary used for mapping\n",
    "    \n",
    "    new_y = np.zeros((y.shape))\n",
    "    for ind, label in enumerate(y):\n",
    "        new_y[ind] = mapper[label]\n",
    "    \n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collate the class-wise averaged accuracy for all regulatisation constants over all seasons\n",
    "reg_constants = [0.01, 0.1, 0.1**0.5, 1, 10**0.5, 10, 100**0.5]\n",
    "seasons = ['spring', 'summer', 'autumn', 'winter']\n",
    "\n",
    "# A matrix to contain the scores of each constans' score for each season, 4 x 7 dimension\n",
    "reg_matrix = np.zeros((len(seasons), len(reg_constants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for constant of 0.01 in season spring, the accuracy was 0.0\n",
      "for constant of 0.01 in season summer, the accuracy was 0.894736842105263\n",
      "for constant of 0.01 in season autumn, the accuracy was 0.2608695652173913\n",
      "for constant of 0.01 in season winter, the accuracy was 0.34375\n",
      "for constant of 0.1 in season spring, the accuracy was 0.0\n",
      "for constant of 0.1 in season summer, the accuracy was 0.8796992481203008\n",
      "for constant of 0.1 in season autumn, the accuracy was 0.21739130434782608\n",
      "for constant of 0.1 in season winter, the accuracy was 0.34375\n",
      "for constant of 0.31622776601683794 in season spring, the accuracy was 0.0\n",
      "for constant of 0.31622776601683794 in season summer, the accuracy was 0.8195488721804511\n",
      "for constant of 0.31622776601683794 in season autumn, the accuracy was 0.21739130434782608\n",
      "for constant of 0.31622776601683794 in season winter, the accuracy was 0.34375\n",
      "for constant of 1 in season spring, the accuracy was 0.0\n",
      "for constant of 1 in season summer, the accuracy was 0.849624060150376\n",
      "for constant of 1 in season autumn, the accuracy was 0.17391304347826086\n",
      "for constant of 1 in season winter, the accuracy was 0.34375\n",
      "for constant of 3.1622776601683795 in season spring, the accuracy was 0.0\n",
      "for constant of 3.1622776601683795 in season summer, the accuracy was 0.8421052631578947\n",
      "for constant of 3.1622776601683795 in season autumn, the accuracy was 0.21739130434782608\n",
      "for constant of 3.1622776601683795 in season winter, the accuracy was 0.34375\n",
      "for constant of 10 in season spring, the accuracy was 0.0\n",
      "for constant of 10 in season summer, the accuracy was 0.8345864661654134\n",
      "for constant of 10 in season autumn, the accuracy was 0.21739130434782608\n",
      "for constant of 10 in season winter, the accuracy was 0.3125\n",
      "for constant of 10.0 in season spring, the accuracy was 0.0\n",
      "for constant of 10.0 in season summer, the accuracy was 0.849624060150376\n",
      "for constant of 10.0 in season autumn, the accuracy was 0.21739130434782608\n",
      "for constant of 10.0 in season winter, the accuracy was 0.34375\n"
     ]
    }
   ],
   "source": [
    "## For each constant, test which each season and append the scores to the matrix\n",
    "for ind, con in  enumerate(reg_constants):\n",
    "    acc_scores = [] # To store the accuracy values for each season\n",
    "    for season in seasons:\n",
    "        # We change the labels for each season to do a One vs All SVM\n",
    "        season_v_all_train = one_for_all(y_train, season)\n",
    "        season_v_all_val = one_for_all(y_val, season)\n",
    "        \n",
    "        # Set up the model\n",
    "        clf = SVC(C=con, kernel='linear', probability=True)\n",
    "        clf.fit(x_train, season_v_all_train)\n",
    "        \n",
    "        # Predict with validation set\n",
    "        pred_y = clf.predict_proba(x_val)\n",
    "        pred_y = np.argmax(pred_y, axis=1)\n",
    "        \n",
    "        # Use class wise accuracy function to calculate accuracy score. We use 1 here as it represents the current \n",
    "        # season's label\n",
    "        acc_score = class_wise_accuracy(season_v_all_val, pred_y, 1)\n",
    "        acc_scores.append(acc_score)\n",
    "            \n",
    "    reg_matrix[:, ind] = acc_scores      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class-wise average accuracy over the 4 seasons for c=0.01 is 0.3748391018306636\n",
      "The class-wise average accuracy over the 4 seasons for c=0.1 is 0.36021013811703173\n",
      "The class-wise average accuracy over the 4 seasons for c=0.31622776601683794 is 0.3451725441320693\n",
      "The class-wise average accuracy over the 4 seasons for c=1 is 0.34182177590715923\n",
      "The class-wise average accuracy over the 4 seasons for c=3.1622776601683795 is 0.3508116418764302\n",
      "The class-wise average accuracy over the 4 seasons for c=10 is 0.3411194426283099\n",
      "The class-wise average accuracy over the 4 seasons for c=10.0 is 0.35269134112455053\n",
      "Overall, the best class-wise average accuracy was with c=0.01\n"
     ]
    }
   ],
   "source": [
    "## Next we average the values in the matrix to check which constant performed the best over all seasons\n",
    "avg = np.average(reg_matrix, axis=0)\n",
    "for ind, x in enumerate(reg_constants):\n",
    "    print(f'The class-wise average accuracy over the 4 seasons for c={reg_constants[ind]} is {avg[ind]}')\n",
    "\n",
    "# In this case we get 0.01 as the best regularisation constant \n",
    "best_c = reg_constants[np.argmax(avg)]\n",
    "print(f'Overall, the best class-wise average accuracy was with c={best_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to use our Constant to test against the combination of train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign the class labels 1,2,3,4 to spring,summer,autumn,winter respectively\n",
    "s_dict = {'spring':1, 'summer':2, 'autumn':3, 'winter':4}\n",
    "\n",
    "# Combine the training and validation sets\n",
    "x_train_val = np.concatenate((x_train, x_val))\n",
    "y_train_val = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use class-wise average metrics to get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class-wise averaged accuracy for c=0.01 is 0.3993223993223993\n"
     ]
    }
   ],
   "source": [
    "## Once again we use One vs All, but we use predict_proba this time\n",
    "\n",
    "# Matrix for storing the True probabilities for each season. \n",
    "# This will be used to find our final predicted labels for vanilla accuracy test. Dimension of len(y_test) x len(seasons)\n",
    "fin_y_pred = np.zeros((len(y_test), len(seasons)))\n",
    "\n",
    "# To store class-wise accuracy scores\n",
    "class_wise_scores = []\n",
    "\n",
    "# One Vs All Probabilities\n",
    "for ind, season in enumerate(seasons):    \n",
    "    # We change the labels for each season to do a One vs All SVM\n",
    "    season_v_all_train_val = one_for_all(y_train_val, season) # train validation labels\n",
    "    season_v_all_test = one_for_all(y_test, season) # test labels\n",
    "    \n",
    "    # Model\n",
    "    clf = SVC(C=best_c, kernel='linear', probability=True)\n",
    "    clf.fit(x_train_val, season_v_all_train_val)\n",
    "    \n",
    "    # Predict probability and take the values that correspond to True\n",
    "    pred_prob = clf.predict_proba(x_test)\n",
    "    sea_y_pred = pred_prob[:,1]\n",
    "    \n",
    "    # Append to fin_y_pred\n",
    "    fin_y_pred[:,ind] = sea_y_pred\n",
    "    \n",
    "    # Use argmax to get the predictions\n",
    "    pred_y = np.argmax(pred_prob, axis=1)\n",
    "    \n",
    "    # Get class wise accuracy and append\n",
    "    acc = class_wise_accuracy(season_v_all_test, pred_y, 1)\n",
    "    class_wise_scores.append(acc)\n",
    "    \n",
    "class_wise_average_accuracy = np.average(class_wise_scores)\n",
    "print(f'The class-wise averaged accuracy for c={best_c} is {class_wise_average_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
       "       2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 4,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2,\n",
       "       4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 4, 1, 2, 2, 2, 2, 2, 2, 1, 2, 4, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 3, 3, 2, 3, 2, 2, 3, 2, 2, 4, 3, 4, 3, 3, 2, 3,\n",
       "       3, 3, 4, 4, 2, 3, 4, 4, 4, 2, 4, 2, 2, 1, 4, 4, 2, 2, 4, 4, 4, 4,\n",
       "       4, 2, 4, 4, 2, 2, 3, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 4, 2, 4,\n",
       "       2, 3, 3, 3, 4, 2, 2, 4, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next we use argmax in the y axis, which gives us a matrix of len(y_test) x 1\n",
    "# And this represents the most probable labels class wise\n",
    "fin_y_pred = np.argmax(fin_y_pred, axis=1) + 1\n",
    "fin_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to test our labels with class-wise  and vanilla accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vanilla accuracy for c=0.01 is 0.7470588235294118\n"
     ]
    }
   ],
   "source": [
    "map_to_num = season_map(y_test, s_dict)\n",
    "\n",
    "vanilla_acc = vanilla_taste_good(map_to_num, fin_y_pred, len(y_test))\n",
    "print(f'The vanilla accuracy for c={best_c} is {vanilla_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
