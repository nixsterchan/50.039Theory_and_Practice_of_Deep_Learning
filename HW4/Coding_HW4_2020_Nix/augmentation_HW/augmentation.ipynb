{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision.transforms import FiveCrop, ToTensor, Lambda, Compose, CenterCrop, Normalize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from data.imagenet import getimagenetclasses as get_labels\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandsomeBinderNet(Dataset):\n",
    "    def __init__(self, img_root, ins_label_pairs , crop_size, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        img_root: contains the path to the image root folder\n",
    "        ins_label_pairs: instance label pair that contains a list of all the image path names and their respective labels\n",
    "        crop_size: contains desired crop dimensions\n",
    "        transform: contains the transformation procedures to be applied. defaulted to be None\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.img_root = img_root\n",
    "        self.ins_label_pairs = ins_label_pairs\n",
    "        self.crop_size = crop_size\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ins_label_pairs)\n",
    "    \n",
    "    def image_load(self, image_path):\n",
    "        # Open image and load\n",
    "        img = (Image.open(image_path))\n",
    "        img.load()\n",
    "        \n",
    "        img = np.array(img)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, 2)\n",
    "            img = np.repeat(img, 3, 2)\n",
    "            \n",
    "        return Image.fromarray(img)\n",
    "    \n",
    "    def image_resize(self, image, crop_size):\n",
    "        W, H = image.size\n",
    "        # Scale according to the lower value between height and width\n",
    "        scale = crop_size / min(W, H)\n",
    "        # New size for resizing       \n",
    "        new_size = (int(np.ceil(scale * W)), int(np.ceil(scale * H)))\n",
    "        \n",
    "        return image.resize(new_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Path to the image\n",
    "        image_path = self.img_root + self.ins_label_pairs[index][0]\n",
    "        \n",
    "        # Open the image\n",
    "        image = self.image_load(image_path)\n",
    "        label = self.ins_label_pairs[index][1]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.image_resize(image, self.crop_size)\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the dataset\n",
    "def prepare_dataloader(img_path, ins_label_pairs, crop_size, transform, bs):\n",
    "    \"\"\"\n",
    "    img_path: path to image root\n",
    "    ins_label_pairs: instance label pairs containing the paths of jpeg images and their respective labels\n",
    "    crop_size: your desired crop size\n",
    "    transform: your transformation sequence\n",
    "    bs: your desired batch size for dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = HandsomeBinderNet(img_path, ins_label_pairs, crop_size=crop_size, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "# Runs evaluation\n",
    "def evaluate(dataloader, model, device, is_fivecrop=False):\n",
    "    \"\"\"\n",
    "    dataloader: dataloader\n",
    "    model: your model\n",
    "    device: what you are using to compute\n",
    "    is_fivecrop: default False. if set to True, it deals with the 5 tensor for problem 2\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Calculate the accuracy\n",
    "    num_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if (is_fivecrop):\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                # Images is a five-tensor\n",
    "                bs, ncrops, c, h, w = images.size()\n",
    "\n",
    "                # fuse batch size and ncrops\n",
    "                result = model(images.view(-1, c, h, w)) \n",
    "\n",
    "                # avg over crops\n",
    "                result_avg = result.view(bs, ncrops, -1).mean(1) \n",
    "\n",
    "                pred = result_avg.argmax(dim=1, keepdim=True)\n",
    "                num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        else:\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                images, labels = batch[0].to(device), batch[1].to(device)\n",
    "                output = model(images)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    print(f'Accuracy: {100 * num_corrects/len(dataloader.dataset)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem1(imgpath, ins_label_pairs, device):\n",
    "    #### Problem 1 Test Performance of a pretrained net with and without normalizing ####\n",
    "    print('Problem 1: Test Performance of a pretrained net with and without normalizing \\n \\n \\n \\n')\n",
    "    \n",
    "    ## Create transformations for normalize and none ##\n",
    "    # No normalize\n",
    "    t_no_normalize = Compose([CenterCrop(224), ToTensor()])\n",
    "    # With normalize\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    t_normalize = Compose([CenterCrop(224), ToTensor(), normalizer])\n",
    "    \n",
    "    # Evaluate without normalize\n",
    "    dataloader = prepare_dataloader(imgpath, ins_label_pairs, 224, t_no_normalize, 16)\n",
    "    model = models.resnet18(pretrained=True).to(device)\n",
    "    print('For Problem 1, in the case without normalization:')\n",
    "    evaluate(dataloader, model, device)\n",
    "    \n",
    "    # Evaluate with normalize\n",
    "    dataloader = prepare_dataloader(imgpath, ins_label_pairs, 224, t_normalize, 16)\n",
    "    model = models.resnet18(pretrained=True).to(device)\n",
    "    print('For Problem 1, in the case without normalization:')\n",
    "    evaluate(dataloader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2(imgpath, ins_label_pairs, device):\n",
    "    #### Problem 2 Test the performance of a pretrained net five crop ####\n",
    "    print('\\n \\n \\n \\nProblem 2: Test the performance of a pretrained net five crop \\n \\n \\n \\n')\n",
    "\n",
    "    # Create transformations for five crop\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    t_five_crop = Compose([FiveCrop(224), \n",
    "                                      Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])),\n",
    "                                      Lambda(lambda crops: torch.stack([normalizer(crop) for crop in crops]))])\n",
    "    # Evaluate\n",
    "    dataloader = prepare_dataloader(imgpath, ins_label_pairs, 280, t_five_crop, 16)\n",
    "    model = models.resnet18(pretrained=True).to(device)\n",
    "    print('For Problem 2, with five crop:')\n",
    "    evaluate(dataloader, model, device, is_fivecrop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem3(imgpath, ins_label_pairs, device):\n",
    "    #### Problem 3 Different input size of neural networks with different pretrained neural nets ####\n",
    "    print('\\n \\n \\n \\nProblem 3: Different input size of neural networks with different pretrained neural nets \\n \\n \\n \\n')\n",
    "    \n",
    "    # Normalize\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    t_normalize = Compose([CenterCrop(224), ToTensor(), normalizer])\n",
    "    \n",
    "    # Create Dataloader\n",
    "    dataloader = prepare_dataloader(imgpath, ins_label_pairs, 330, t_normalize, 16)\n",
    "\n",
    "    # Evaluate for DenseNet 161\n",
    "    model = models.densenet161(pretrained=True).to(device)\n",
    "    print('For Problem 3, using the Dense Net 161:')\n",
    "    evaluate(dataloader, model, device)\n",
    "    \n",
    "    # Evaluate for GoogleNet\n",
    "    model = models.googlenet(pretrained=True).to(device)\n",
    "    print('For Problem 3, using the Google Net:')\n",
    "    evaluate(dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Get path for images and their JPEG path (Change this if needed!)\n",
    "    imgpath = 'data/imagenet/imagenet2500/imagespart/'\n",
    "\n",
    "    # Store the JPEG path names into a list\n",
    "    onlyfiles = [f for f in listdir(imgpath) if isfile(join(imgpath, f))]\n",
    "    \n",
    "    # Get the JPEG file paths and their respective labels into a instance-label list\n",
    "    ins_label_pairs = []\n",
    "    for JPEG in onlyfiles:\n",
    "        ins_label_pairs.append([JPEG , get_labels.test_parseclasslabel(JPEG)])\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
    "    \n",
    "    # Problem 1\n",
    "    problem1(imgpath, ins_label_pairs, device)\n",
    "    # Problem 2\n",
    "    problem2(imgpath, ins_label_pairs, device)\n",
    "    # Problem 3\n",
    "    problem3(imgpath, ins_label_pairs, device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 1: Test Performance of a pretrained net with and without normalizing \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "For Problem 1, in the case without normalization:\n",
      "Accuracy: 44.04%\n",
      "For Problem 1, in the case without normalization:\n",
      "Accuracy: 70.08%\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " Problem 2: Test the performance of a pretrained net five crop \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "For Problem 2, with five crop:\n",
      "Accuracy: 72.88%\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " Problem 3: Different input size of neural networks with different pretrained neural nets \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "For Problem 3, using the Dense Net 161:\n",
      "Accuracy: 76.0%\n",
      "For Problem 3, using the Google Net:\n",
      "Accuracy: 68.96%\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
