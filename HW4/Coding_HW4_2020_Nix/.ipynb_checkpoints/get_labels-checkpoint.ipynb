{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision.transforms import FiveCrop, ToTensor, Lambda, Compose, CenterCrop, Normalize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from data.imagenet import getimagenetclasses as get_labels\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path for images and their JPEG path\n",
    "mypath = 'data/imagenet/imagenet2500/imagespart/'\n",
    "\n",
    "# Store the JPEG path names into a list\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the JPEG file paths and their respective labels into a instance-label list\n",
    "ins_label_pairs = []\n",
    "\n",
    "for JPEG in onlyfiles:\n",
    "    ins_label_pairs.append([JPEG ,get_labels.test_parseclasslabel(JPEG)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandsomeBinderNet(Dataset):\n",
    "    def __init__(self, img_root, ins_label_pairs , crop_size, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        img_root: contains the path to the image root folder\n",
    "        ins_label_pairs: instance label pair that contains a list of all the image path names and their respective labels\n",
    "        crop_size: contains desired crop dimensions\n",
    "        transform: contains the transformation procedures to be applied. defaulted to be None\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.img_root = img_root\n",
    "        self.ins_label_pairs = ins_label_pairs\n",
    "        self.crop_size = crop_size\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ins_label_pairs)\n",
    "    \n",
    "    def image_load(self, image_path):\n",
    "        # Open image and load\n",
    "        img = (Image.open(image_path))\n",
    "        img.load()\n",
    "        \n",
    "        img = np.array(img)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, 2)\n",
    "            img = np.repeat(img, 3, 2)\n",
    "            \n",
    "        return Image.fromarray(img)\n",
    "    \n",
    "    def image_resize(self, image, crop_size):\n",
    "        W, H = image.size\n",
    "        # Scale according to the lower value between height and width\n",
    "        scale = crop_size / min(W, H)\n",
    "        # New size for resizing       \n",
    "        new_size = (int(np.ceil(scale * W)), int(np.ceil(scale * H)))\n",
    "        \n",
    "        return image.resize(new_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Path to the image\n",
    "        image_path = self.img_root + self.ins_label_pairs[index][0]\n",
    "        \n",
    "        # Open the image\n",
    "        image = self.image_load(image_path)\n",
    "        label = self.ins_label_pairs[index][1]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.image_resize(image, self.crop_size)\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Task: Test the performance of a pretrained net - simple crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformations for normalize and none\n",
    "\n",
    "# No normalize\n",
    "t_no_normalize = Compose([CenterCrop(224), ToTensor()])\n",
    "\n",
    "# With normalize\n",
    "normalizer = Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "t_normalize = Compose([CenterCrop(224), ToTensor(), normalizer])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(img_path, ins_label_pairs, crop_size, transform, bs):\n",
    "    \"\"\"\n",
    "    img_path: path to image root\n",
    "    ins_label_pairs: instance label pairs containing the paths of jpeg images and their respective labels\n",
    "    crop_size: your desired crop size\n",
    "    transform: your transformation sequence\n",
    "    bs: your desired batch size for dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = HandsomeBinderNet(img_path, ins_label_pairs, crop_size=crop_size, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "def evaluate(dataloader, model, device, is_fivecrop=False):\n",
    "    \"\"\"\n",
    "    dataloader: dataloader\n",
    "    model: your model\n",
    "    device: what you are using to compute\n",
    "    is_fivecrop: default False. if set to True, it deals with the 5 tensor for problem 2\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Calculate the accuracy\n",
    "    num_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if (is_fivecrop):\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                images, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "                # Images is a five-tensor\n",
    "                bs, ncrops, c, h, w = images.size()\n",
    "\n",
    "                # fuse batch size and ncrops\n",
    "                result = model(images.view(-1, c, h, w)) \n",
    "\n",
    "                # avg over crops\n",
    "                result_avg = result.view(bs, ncrops, -1).mean(1) \n",
    "\n",
    "                pred = result_avg.argmax(dim=1, keepdim=True)\n",
    "                num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        else:\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                images, labels = batch[0].to(device), batch[1].to(device)\n",
    "                output = model(images)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    print(f'Test set: Accuracy: {100 * num_corrects/len(dataloader.dataset)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = prepare_dataloader(mypath, ins_label_pairs, 224, t_no_normalize, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True).to(device)\n",
    "evaluate(dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = HandsomeBinderNet('data/imagenet/imagenet2500/imagespart/', ins_label_pairs, crop_size=224, transform=t_no_normalize)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Create the model with pretrained weights\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Calculate the accuracy\n",
    "num_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        output = model(images)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(num_corrects, len(dataloader.dataset), \n",
    "                                                       100. * num_corrects / len(dataloader.dataset)))         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def \n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = HandsomeBinderNet('data/imagenet/imagenet2500/imagespart/', ins_label_pairs, crop_size=224, transform=t_normalize)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Create the model with pretrained weights\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Task: Test the performance of a pretrained net - five crop (see be-low if you cannot use a five crop transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformations for five crop\n",
    "t_five_crop = transforms.Compose([FiveCrop(224), \n",
    "                                  Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])),\n",
    "                                  Lambda(lambda crops: torch.stack([normalizer(crop) for crop in crops]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = HandsomeBinderNet('data/imagenet/imagenet2500/imagespart/', ins_label_pairs, crop_size=280, transform=t_five_crop)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Create the model with pretrained weights\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Calculate the accuracy\n",
    "num_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        # Images is a five-tensor\n",
    "        bs, ncrops, c, h, w = images.size()\n",
    "        \n",
    "        # fuse batch size and ncrops\n",
    "        result = model(images.view(-1, c, h, w)) \n",
    "        \n",
    "        # avg over crops\n",
    "        result_avg = result.view(bs, ncrops, -1).mean(1) \n",
    "        \n",
    "        pred = result_avg.argmax(dim=1, keepdim=True)\n",
    "        num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(num_corrects, len(dataloader.dataset), \n",
    "                                                       100. * num_corrects / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Task : Different input size of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dense Net 161\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = HandsomeBinderNet('data/imagenet/imagenet2500/imagespart/', ins_label_pairs, crop_size=330, transform=t_normalize)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Create the model with pretrained weights\n",
    "# model = models.resnet18(pretrained=True).to(device)\n",
    "model = models.densenet161(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Calculate the accuracy\n",
    "num_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        output = model(images)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(num_corrects, len(dataloader.dataset), \n",
    "                                                       100. * num_corrects / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Google Net\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = HandsomeBinderNet('data/imagenet/imagenet2500/imagespart/', ins_label_pairs, crop_size=330, transform=t_normalize)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Create the model with pretrained weights\n",
    "# model = models.resnet18(pretrained=True).to(device)\n",
    "model = models.googlenet(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Calculate the accuracy\n",
    "num_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        output = model(images)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        num_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    \n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(num_corrects, len(dataloader.dataset), \n",
    "                                                       100. * num_corrects / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem1(imgpath, ins_label_pairs, device):\n",
    "    #### Problem 1 Test Performance of a pretrained net with and without normalizing ####\n",
    "    print('Problem 1: Test Performance of a pretrained net with and without normalizing \\n \\n \\n \\n')\n",
    "    \n",
    "    ## Create transformations for normalize and none ##\n",
    "    # No normalize\n",
    "    t_no_normalize = Compose([CenterCrop(224), ToTensor()])\n",
    "    # With normalize\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    t_normalize = Compose([CenterCrop(224), ToTensor(), normalizer])\n",
    "    \n",
    "    # Evaluate without normalize\n",
    "    dataloader = prepare_dataloader(imgpath, ins_label_pairs, 224, t_no_normalize, 16)\n",
    "    model = models.resnet18(pretrained=True).to(device)\n",
    "    print('For Problem 1, in the case without normalization:')\n",
    "    evaluate(dataloader, model, device)\n",
    "    \n",
    "    # Evaluate with normalize\n",
    "    dataloader = prepare_dataloader(imgpath, ins_label_pairs, 224, t_normalize, 16)\n",
    "    model = models.resnet18(pretrained=True).to(device)\n",
    "    print('For Problem 1, in the case without normalization:')\n",
    "    evaluate(dataloader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2(imgpath, ins_label_pairs, device):\n",
    "    #### Problem 2 Test the performance of a pretrained net five crop ####\n",
    "    print('\\n \\n \\n \\n Problem 2: Test the performance of a pretrained net five crop \\n \\n \\n \\n')\n",
    "\n",
    "    # Create transformations for five crop\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    t_five_crop = Compose([FiveCrop(224), \n",
    "                                      Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])),\n",
    "                                      Lambda(lambda crops: torch.stack([normalizer(crop) for crop in crops]))])\n",
    "    # Evaluate\n",
    "    dataloader = prepare_dataloader(imgpath, ins_label_pairs, 280, t_five_crop, 16)\n",
    "    model = models.resnet18(pretrained=True).to(device)\n",
    "    print('For Problem 2, with five crop:')\n",
    "    evaluate(dataloader, model, device, is_fivecrop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem3(imgpath, ins_label_pairs, device):\n",
    "    #### Problem 3 Different input size of neural networks with different pretrained neural nets ####\n",
    "    print('\\n \\n \\n \\n Problem 3: Different input size of neural networks with different pretrained neural nets \\n \\n \\n \\n')\n",
    "    \n",
    "    # Normalize\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    t_normalize = Compose([CenterCrop(224), ToTensor(), normalizer])\n",
    "    \n",
    "    # Create Dataloader\n",
    "    dataloader = HandsomeBinderNet(imgpath, ins_label_pairs, 330, t_normalize, 16)\n",
    "\n",
    "    # Evaluate for DenseNet 161\n",
    "    model = models.densenet161(pretrained=True).to(device)\n",
    "    print('For Problem 3, using the Dense Net 161:')\n",
    "    evaluate(dataloader, model, device)\n",
    "    \n",
    "    # Evaluate for GoogleNet\n",
    "    model = models.googlenet(pretrained=True).to(device)\n",
    "    print('For Problem 3, using the Google Net:')\n",
    "    evaluate(dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Get path for images and their JPEG path\n",
    "    imgpath = 'data/imagenet/imagenet2500/imagespart/'\n",
    "\n",
    "    # Store the JPEG path names into a list\n",
    "    onlyfiles = [f for f in listdir(imgpath) if isfile(join(imgpath, f))]\n",
    "    \n",
    "    # Get the JPEG file paths and their respective labels into a instance-label list\n",
    "    ins_label_pairs = []\n",
    "    for JPEG in onlyfiles:\n",
    "        ins_label_pairs.append([JPEG , get_labels.test_parseclasslabel(JPEG)])\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
    "    \n",
    "    # Problem 1\n",
    "    problem1(imgpath, ins_label_pairs, device)\n",
    "    # Problem 2\n",
    "    problem2(imgpath, ins_label_pairs, device)\n",
    "    # Problem 3\n",
    "    problem3(imgpath, ins_label_pairs, device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 1: Test Performance of a pretrained net with and without normalizing \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "For Problem 1, in the case without normalization:\n",
      "Test set: Accuracy: 44.04%\n",
      "For Problem 1, in the case without normalization:\n",
      "Test set: Accuracy: 70.08%\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " Problem 2: Test the performance of a pretrained net five crop \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "For Problem 2, with five crop:\n",
      "Test set: Accuracy: 72.88%\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " Problem 3: Different input size of neural networks with different pretrained neural nets \n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 't_normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-c18a2cb8fab0>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mproblem2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mins_label_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Problem 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mproblem3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mins_label_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-48edd844bca7>\u001b[0m in \u001b[0;36mproblem3\u001b[1;34m(imgpath, ins_label_pairs, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Create Dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHandsomeBinderNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mins_label_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m330\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_normalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Evaluate for DenseNet 161\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't_normalize' is not defined"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
